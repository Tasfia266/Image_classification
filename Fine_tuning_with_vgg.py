# -*- coding: utf-8 -*-
"""Feature_extraction_vgg_aug.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PrA-9Oq_PZlq5aawETENfZSBQbAvlQNd
"""

from keras.applications import VGG16
conv_base= VGG16 (weights='imagenet', include_top= False, input_shape= (150,150,3))

from google.colab import drive 
drive.mount ('/content/drive')

train_dir= '/content/drive/MyDrive/Cats_and_dogs/train'

validation_dir= '/content/drive/MyDrive/Cats_and_dogs/validation'

test_dir='/content/drive/MyDrive/Cats_and_dogs/test'

from keras import layers 
from keras import models 
model=models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add (layers.Dense (256, activation='relu'))
model.add(layers.Dense (1, activation='sigmoid'))

model.summary()

conv_base.trainable=False

len(model.trainable_weights)

from keras import optimizers
model.compile (loss='binary_crossentropy', optimizer=optimizers.Adam (learning_rate= 0.01), metrics=['accuracy'] )

# image preprocessing
from keras.preprocessing.image import ImageDataGenerator
train_datagen= ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,
                                  zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')

train_generator= train_datagen.flow_from_directory(train_dir, target_size=(150,150), batch_size=20, class_mode='binary')

validation_datagen= ImageDataGenerator(rescale=1./255) #dont augment the validation data

validation_generator= validation_datagen.flow_from_directory(validation_dir, target_size=(150,150), batch_size=20, class_mode='binary')

history= model.fit_generator (train_generator, steps_per_epoch=100, epochs=30, validation_data=validation_generator, validation_steps=50)

# testing on test data
test_datagen= ImageDataGenerator(rescale=1./255)

test_generator= test_datagen.flow_from_directory(test_dir, target_size= (150,150), batch_size=20, class_mode='binary')

model.evaluate (test_generator)

#Fine tuning

"""**Fine** **tuning**"""

# freezing all layers upto specific one
conv_base.trainable= True 
set_trainable= False 
for layer in conv_base.layers:
  if layer.name=='block5_conv1':
    set_trainable= True 
  if set_trainable:
    layer.trainable=True 
  else:
    layer.trainable= False

# fine tuning the model with a very low learning rate
model.compile (loss='binary_crossentropy', optimizer= optimizers.RMSprop(lr=1e-5), metrics=['accuracy'])

history= model.fit_generator(train_generator, steps_per_epoch=100, epochs=30, validation_data=validation_generator, validation_steps=50)

import matplotlib.pyplot as plt
acc= history.history['accuracy']
val_acc= history.history['val_accuracy']
loss= history.history['loss']
val_loss= history.history['val_loss']

epochs= range (1, len(acc)+1)
plt.plot (epochs, acc, 'bo', label= 'Training accuracy')
plt.plot (epochs, val_acc, 'b', label='Validation_accuracy')
plt.title ('Training and Validation accuracy')
plt.legend ()
plt.figure ()

plt.plot (epochs, loss, 'bo', label='Training Loss')
plt.plot (epochs, val_loss, 'b', label='Validation Loss')
plt.title ('Training and Validation Loss')
plt.legend ()
plt.show ()

